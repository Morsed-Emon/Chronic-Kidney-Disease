# -*- coding: utf-8 -*-
"""Thesis2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y7PDx9RdV3JtbGMT0Jk24tSDtAmEg3XQ

### Importing Necessary Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

import warnings
warnings.filterwarnings('ignore')

plt.style.use('fivethirtyeight')
# %matplotlib inline
pd.set_option('display.max_columns', 26)

path = "/content/drive/MyDrive/Kidney_Dataset/kidney_disease.csv"

from google.colab import drive
drive.mount('/content/drive')

"""### Reading the dataset"""

# loading data

df= pd.read_csv('kidney_disease_dataset.csv')
df.head()

df.shape

df.drop('id', axis = 1, inplace = True)

df.columns = ['age', 'blood_pressure', 'specific_gravity', 'albumin', 'sugar', 'red_blood_cells', 'pus_cell',
              'pus_cell_clumps', 'bacteria', 'blood_glucose_random', 'blood_urea', 'serum_creatinine', 'sodium',
              'potassium', 'haemoglobin', 'packed_cell_volume', 'white_blood_cell_count', 'red_blood_cell_count',
              'hypertension', 'diabetes_mellitus', 'coronary_artery_disease', 'appetite', 'peda_edema',
              'aanemia', 'class']

df.head()

df.describe()

df.info()

# converting necessary columns to numerical type

df['packed_cell_volume'] = pd.to_numeric(df['packed_cell_volume'], errors='coerce')
df['white_blood_cell_count'] = pd.to_numeric(df['white_blood_cell_count'], errors='coerce')
df['red_blood_cell_count'] = pd.to_numeric(df['red_blood_cell_count'], errors='coerce')

df.info()

# Extracting categorical and numerical columns

cat_cols = [col for col in df.columns if df[col].dtype == 'object']
num_cols = [col for col in df.columns if df[col].dtype != 'object']

# looking at unique values in categorical columns

for col in cat_cols:
    print(f"{col} has {df[col].unique()} values\n")

# replace incorrect values

df['diabetes_mellitus'].replace(to_replace = {'\tno':'no','\tyes':'yes',' yes':'yes'},inplace=True)

df['coronary_artery_disease'] = df['coronary_artery_disease'].replace(to_replace = '\tno', value='no')

df['class'] = df['class'].replace(to_replace = {'ckd\t': 'ckd', 'notckd': 'not ckd'})

df['class'] = df['class'].map({'ckd': 0, 'not ckd': 1})
df['class'] = pd.to_numeric(df['class'], errors='coerce')

cols = ['diabetes_mellitus', 'coronary_artery_disease', 'class']

for col in cols:
    print(f"{col} has {df[col].unique()} values\n")

# checking numerical features distribution

plt.figure(figsize = (20, 15))
plotnumber = 1

for column in num_cols:
    if plotnumber <= 14:
        ax = plt.subplot(3, 5, plotnumber)
        sns.distplot(df[column])
        plt.xlabel(column)

    plotnumber += 1

plt.tight_layout()
plt.show()

# looking at categorical columns

plt.figure(figsize = (20, 15))
plotnumber = 1

for column in cat_cols:
    if plotnumber <= 11:
        ax = plt.subplot(3, 4, plotnumber)
        sns.countplot(df[column], palette = 'rocket')
        plt.xlabel(column)

    plotnumber += 1

plt.tight_layout()
plt.show()

# heatmap of data


fig, ax = plt.subplots(figsize = (16, 8))
sns.heatmap(df.corr(), annot = True, linewidths = 2, linecolor = 'lightgrey',fmt='.4f',
            cmap=plt.get_cmap('coolwarm'), cbar=False, ax=ax)
ax.set_yticklabels(ax.get_yticklabels(), rotation="horizontal")
plt.show()
plt.savefig('corr1.png', bbox_inches='tight', pad_inches=0.0)

correlations = df.corr()['class'].sort_values()

# Display correlations
print('Most Positive Correlations:\n', correlations.tail())
print('\nMost Negative Correlations:\n', correlations.head())
# Make a table

df.columns

"""### Data Preprocessing"""

# checking for null values

df.isna().sum().sort_values(ascending = False)

df[num_cols].isnull().sum()

df[cat_cols].isnull().sum()

# filling null values, we will use two methods, random sampling for higher null values and
# mean/mode sampling for lower null values

def random_value_imputation(feature):
    random_sample = df[feature].dropna().sample(df[feature].isna().sum())
    random_sample.index = df[df[feature].isnull()].index
    df.loc[df[feature].isnull(), feature] = random_sample

def impute_mode(feature):
    mode = df[feature].mode()[0]
    df[feature] = df[feature].fillna(mode)

# filling num_cols null values using random sampling method

for col in num_cols:
    random_value_imputation(col)

df[num_cols].isnull().sum()

# filling "red_blood_cells" and "pus_cell" using random sampling method and rest of cat_cols using mode imputation

random_value_imputation('red_blood_cells')
random_value_imputation('pus_cell')

for col in cat_cols:
    impute_mode(col)

df[cat_cols].isnull().sum()

"""### Feature Encoding"""

for col in cat_cols:
    print(f"{col} has {df[col].nunique()} categories\n")

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

for col in cat_cols:
    df[col] = le.fit_transform(df[col])

df.head()

ind_col = [col for col in df.columns if col != 'class']
dep_col = 'class'

X = df[ind_col]
y = df[dep_col]

X.shape

y

plt.figure(figsize = (20, 8))

sns.heatmap(df.corr(), annot = True, linewidths = 2, linecolor = 'lightgrey')
plt.show()
plt.savefig('correlation.png')

# Find correlations with the target and sort
correlations = df.corr()['class'].sort_values()

# Display correlations
print('Most Positive Correlations:\n', correlations.tail())
print('\nMost Negative Correlations:\n', correlations.head())

# MENTION IN PAPER

from sklearn.preprocessing import MinMaxScaler,StandardScaler
scaler = MinMaxScaler()
scaler.fit(X)
# scaler1 = StandardScaler()
# scaler1.fit(X)

new_features = scaler.transform(X)
print(new_features)

df

X

from sklearn.feature_selection import SelectKBest, chi2, f_regression, f_classif
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import Lasso
import pandas as pd

# Assuming X contains features and y contains the target variable

# Feature selection using filter methods
# Pearson Correlation
pearson_correlation = abs(X.corrwith(y)) > 0.3  # Adjust threshold as needed

# Chi Square
chi2_selector = SelectKBest(chi2, k='all')
chi2_selector.fit(X, y)
chi2_scores = chi2_selector.scores_ > 10  # Adjust threshold as needed

# Feature selection using embedded methods
# Lasso L1
lasso_selector = SelectKBest(score_func=f_regression, k='all')
lasso_selector.fit(X, y)
lasso_support = lasso_selector.get_support()

# Tree-based technique (Random Forest)
rf_selector = RandomForestClassifier()
rf_selector.fit(X, y)
rf_importances = rf_selector.feature_importances_
rf_support = rf_importances > np.mean(rf_importances)

# Univariate Selection
univariate_selector = SelectKBest(score_func=f_classif, k='all')
univariate_selector.fit(X, y)
univariate_support = univariate_selector.get_support()

# Create a DataFrame to store the results
feature_selection_results = pd.DataFrame({
    'Features': X.columns,
    'Pearson': pearson_correlation,
    'Chi-2': chi2_scores,
    'Logistic': univariate_support,
    'Random Forest': rf_support,
    'Lasso': lasso_support,
})

# Convert boolean values to 'True' or 'False' strings
feature_selection_results = feature_selection_results.replace({True: 'True', False: 'False'})

# Count the total number of 'True' values for each feature
feature_selection_results['Total'] = feature_selection_results[['Pearson', 'Chi-2', 'Logistic', 'Random Forest', 'Lasso']].apply(lambda x: x.eq('True').sum(), axis=1)

# Sort the DataFrame by the 'Total' column in descending order
feature_selection_results = feature_selection_results.sort_values(by='Total', ascending=False)

# Select the best 12 features based on total count
selected_features = feature_selection_results.head(15)['Features'].tolist()

# Print the table
print("Feature Selection Results:")
print(feature_selection_results)

# Print the selected features
print("\nSelected features:")
print(selected_features)

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

# Assuming feature_selection_results contains selected features
selected_features = feature_selection_results.head(12)['Features'].tolist()

# Extract selected features from the original dataset
X_selected = X[selected_features]

# Set the seed for reproducibility
np.random.seed(42)

# Define the number of augmented samples you want to create
num_augmented_samples = 5

# Initialize lists to store augmented data
augmented_X = []
augmented_y = []

# Loop to create augmented samples
for _ in range(num_augmented_samples):
    # Add Gaussian noise to the scaled features
    noise = np.random.normal(0, 0.1, size=X_selected.shape)
    augmented_sample = X_selected + noise

    # Clip the augmented sample to ensure values remain in the range [0, 1]
    augmented_sample = np.clip(augmented_sample, 0, 1)

    augmented_X.append(augmented_sample)
    augmented_y.append(y)

# Convert lists to NumPy arrays
augmented_X = np.vstack(augmented_X)
augmented_y = np.concatenate(augmented_y)

# Split augmented data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(augmented_X, augmented_y, test_size=0.2, random_state=42)

# Apply SMOTE to balance the training set
smote = SMOTE(sampling_strategy='auto', random_state=42)
X_train, y_train = smote.fit_resample(X_train, y_train)

from mlxtend.plotting import plot_confusion_matrix

# Count the number of samples for each class in the augmented training set
unique_classes_train, class_counts_train = np.unique(y_train, return_counts=True)
print("Class Distribution in the Augmented Training Set:")
for cls, count in zip(unique_classes_train, class_counts_train):
    print(f"Class {cls}: {count} samples")

"""### KNN classifier"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

knn = KNeighborsClassifier()
knn.fit(X_train,y_train)

knn_acc = accuracy_score(y_test,knn.predict(X_test))
print(f"Training Accuracy of KNN is {accuracy_score(y_train, knn.predict(X_train))}")
print(f"Test Accuracy of KNN is {knn_acc} \n")
print(f"Classification Report :- \n {classification_report(y_test, knn.predict(X_test))}")
fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, knn.predict(X_test)))
plt.show()

from sklearn.metrics import recall_score,precision_score,f1_score

f1_score(y_test, knn.predict(X_test))

"""### Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier(random_state=67)
dtc.fit(X_train,y_train)
dtc_acc = accuracy_score(y_test,dtc.predict(X_test))
print(f"Training Accuracy of KNN is {accuracy_score(y_train, dtc.predict(X_train))}")
print(f"Test Accuracy of KNN is {dtc_acc} \n")
print(f"Classification Report :- \n {classification_report(y_test, dtc.predict(X_test))}")
fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, dtc.predict(X_test)))
plt.show()

"""### hyperparamter tuning of decision tree"""

from sklearn.model_selection import GridSearchCV
grid_param = {
    'criterion' : ['gini', 'entropy'],
    'max_depth' : [3, 5],
    'splitter' : ['best', 'random'],
    'min_samples_leaf' : [1, 2, 3, 5],
    'min_samples_split' : [1, 2, 3, 5],
    'max_features' : ['auto', 'sqrt', 'log2']
}
grid_search_dtc = GridSearchCV(dtc, grid_param, cv = 5, n_jobs = -1, verbose = 1)
grid_search_dtc.fit(X_train, y_train)

print(grid_search_dtc.best_params_)
print(grid_search_dtc.best_score_)

# best estimator

dtc = grid_search_dtc.best_estimator_

# accuracy score, confusion matrix and classification report of decision tree

dtc_acc = accuracy_score(y_test, dtc.predict(X_test))

print(f"Training Accuracy of Decision Tree Classifier is {accuracy_score(y_train, dtc.predict(X_train))}")
print(f"Test Accuracy of Decision Tree Classifier is {dtc_acc} \n")
print(f"Classification Report :- \n {classification_report(y_test, dtc.predict(X_test))}")
fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, dtc.predict(X_test)))
plt.show()

"""### Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
rd_clf = RandomForestClassifier(random_state=67)
rd_clf.fit(X_train, y_train)

rd_clf_acc = accuracy_score(y_test, rd_clf.predict(X_test))
print(f"Training Accuracy of Random Forest Classifier is {accuracy_score(y_train, rd_clf.predict(X_train))}")
print(f"Test Accuracy of Random Forest Classifier is {rd_clf_acc} \n")
print(f"Classification Report :- \n {classification_report(y_test, rd_clf.predict(X_test))}")
fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, rd_clf.predict(X_test)))
plt.show()

precision_score(y_test, rd_clf.predict(X_test))

"""# Gradient Boost Classifier"""

from sklearn.ensemble import GradientBoostingClassifier

gb = GradientBoostingClassifier(random_state=67)
gb.fit(X_train, y_train)

# accuracy score, confusion matrix and classification report of gradient boosting classifier

gb_acc = accuracy_score(y_test, gb.predict(X_test))

print(f"Training Accuracy of Gradient Boosting Classifier is {accuracy_score(y_train, gb.predict(X_train))}")
print(f"Test Accuracy of Gradient Boosting Classifier is {gb_acc} \n")
print(f"Classification Report :- \n {classification_report(y_test, gb.predict(X_test))}")
fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, gb.predict(X_test)))
plt.show()

"""# Stochastic Gradient Boosting"""

sgb = GradientBoostingClassifier(random_state=67)

sgb.fit(X_train, y_train)

sgb_acc = accuracy_score(y_test, sgb.predict(X_test))

print(f"Training Accuracy of Stochastic Gradient Boosting is {accuracy_score(y_train, sgb.predict(X_train))}")
print(f"Test Accuracy of Stochastic Gradient Boosting is {sgb_acc} \n")
print(f"Classification Report :- \n {classification_report(y_test, sgb.predict(X_test))}")
fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, sgb.predict(X_test)))
plt.show()

pip install catboost

"""# Cat Boost Classifier"""

from catboost import CatBoostClassifier

cat = CatBoostClassifier(iterations=4)
cat.fit(X_train, y_train)

cat_acc = accuracy_score(y_test, cat.predict(X_test))

print(f"Training Accuracy of Cat Boost Classifier is {accuracy_score(y_train, cat.predict(X_train))}")
print(f"Test Accuracy of Cat Boost Classifier is {cat_acc} \n")
print(f"Classification Report :- \n {classification_report(y_test, cat.predict(X_test))}")

fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, cat.predict(X_test)))
plt.show()

"""# Extra Tree Classifier"""

from sklearn.ensemble import ExtraTreesClassifier

etc = ExtraTreesClassifier(random_state=67)
etc.fit(X_train, y_train)

# accuracy score, confusion matrix and classification report of extra trees classifier

etc_acc = accuracy_score(y_test, etc.predict(X_test))

print(f"Training Accuracy of Extra Trees Classifier is {accuracy_score(y_train, etc.predict(X_train))}")
print(f"Test Accuracy of Extra Trees Classifier is {etc_acc} \n")
print(f"Classification Report :- \n {classification_report(y_test, etc.predict(X_test))}")
fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, etc.predict(X_test)))
plt.show()

"""

# LGBM Classifier"""

from lightgbm import LGBMClassifier

lgbm = LGBMClassifier(learning_rate = 0.01)
lgbm.fit(X_train, y_train)

# accuracy score, confusion matrix and classification report of lgbm classifier

lgbm_acc = accuracy_score(y_test, lgbm.predict(X_test))

print(f"Training Accuracy of LGBM Classifier is {accuracy_score(y_train, lgbm.predict(X_train))}")
print(f"Test Accuracy of LGBM Classifier is {lgbm_acc} \n")
print(classification_report(y_test, lgbm.predict(X_test)))
fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix(y_test, lgbm.predict(X_test)))
plt.show()

models = pd.DataFrame({
    'Model' : [ 'KNN', 'Decision Tree Classifier', 'Random Forest Classifier',
             'Gradient Boosting Classifier', 'Stochastic Gradient Boosting','Cat Boost', 'Extra Trees Classifier','LGBM Classifier'],
    'Test_Score' : [knn_acc, dtc_acc, rd_clf_acc, gb_acc, sgb_acc, cat_acc, etc_acc,lgbm_acc]
})

models.sort_values(by = 'Test_Score', ascending = False)

px.bar(data_frame = models, x = 'Test_Score', y = 'Model', color = 'Test_Score', template = 'plotly_dark',
       title = 'Models Comparison')

import tensorflow
from tensorflow import keras
from keras import layers , Input
from tensorflow.keras.models import Model
from tensorflow.keras.utils import  plot_model
from keras.models import Sequential
from keras.layers import Dense, Activation
from keras.layers import Dropout
from keras import layers

from IPython.display import clear_output
class PlotLosses(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.i = 0
        self.x = []
        self.losses = []
        self.val_losses = []
        self.accuracy=[]
        self.val_accuracy=[]

        self.fig = plt.figure()

        self.logs = []

    def on_epoch_end(self, epoch, logs={}):

        self.logs.append(logs)
        self.x.append(self.i)
        self.losses.append(logs.get('loss'))
        self.val_losses.append(logs.get('val_loss'))
        self.accuracy.append(logs.get('accuracy'))
        self.val_accuracy.append(logs.get('val_accuracy'))

        self.i += 1

        clear_output(wait=True)
        plt.plot(self.x, self.losses, label="loss")
        plt.plot(self.x, self.val_losses, label="val_loss")
        plt.legend()
        plt.show();

plot_losses = PlotLosses()

# Initialising the ANN
model_S = Sequential()

# Adding the input layer and the first hidden layer
model_S.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu', input_dim = 15))
model_S.add(Dropout(rate = 0.1))

# Adding the second hidden layer
model_S.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))
model_S.add(Dropout(rate = 0.1))

# Adding the third hidden layer
model_S.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))
model_S.add(Dropout(rate = 0.1))


# Adding the output layer
model_S.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))

# Compiling the ANN
model_S.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

model_S.summary()

plot_model(model_S, to_file='model.png', show_shapes=True)

from keras.models import Sequential
from keras.layers import Dense

# Assuming you have already defined the selected number of features
num_features = 12

# Define your model
model_S = Sequential([
    Dense(64, activation='relu', input_shape=(num_features,)),
    Dense(32, activation='relu'),
    Dense(1, activation='sigmoid')
])

# Compile the model
model_S.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model_S.fit(X_train, y_train, epochs=100, batch_size=8, verbose=2, validation_split=0.2, callbacks=[plot_losses])

score1 = model_S.evaluate(X_train,
                       y_train,
                       verbose=0)
print("\nTrain accuracy: %.1f%%" % (100.0 * score1[1]))

# model accuracy on test dataset
score = model_S.evaluate(X_test,
                       y_test,
                       verbose=0)
print("\nTest accuracy: %.1f%%" % (100.0 * score[1]))

eval_score = model_S.evaluate(X_test, y_test)
print("Test loss:", eval_score[0])
print("Test accuracy:", eval_score[1])

from sklearn.metrics import recall_score

y_hat = model_S.predict(X_test)

y_hat.round()

print(classification_report(y_test, y_hat.round()))

models = pd.DataFrame({
    'Model' : [ 'KNN', 'Decision Tree Classifier', 'Random Forest Classifier',
             'Gradient Boosting Classifier', 'Stochastic Gradient Boosting','Cat Boost', 'Extra Trees Classifier','LGBM Classifier',"ANN"],
    'Training_Score' : [accuracy_score(y_train, knn.predict(X_train)),accuracy_score(y_train, dtc.predict(X_train)),accuracy_score(y_train, rd_clf.predict(X_train)),
                        accuracy_score(y_train, gb.predict(X_train)),accuracy_score(y_train, sgb.predict(X_train)),
                        accuracy_score(y_train, cat.predict(X_train)),accuracy_score(y_train, etc.predict(X_train)),accuracy_score(y_train, lgbm.predict(X_train)),score1[1]],
    'Test_Score' : [knn_acc, dtc_acc, rd_clf_acc, gb_acc, sgb_acc, cat_acc, etc_acc,lgbm_acc,(score[1])]

})

models.sort_values(by = 'Test_Score', ascending = False)

pip install -U kaleido

fig = px.bar(models, x='Model', y = 'Test_Score',color = 'Test_Score',
            title="Models Comparison")
fig.update_layout(xaxis={'categoryorder': 'total ascending'})
fig.show()

pip install matplotlib --upgrade

import matplotlib.pyplot as plt
import numpy as np

Model = ( 'KNN', 'DTC', 'RFC',
             'GBC', 'SGB','CB', 'ETC','LGBM',"ANN")

"""# Without Normalization"""

precision1 = [49
,93
,100
,93
,93
,90
,100
,93
,77
]
prnorm1=[98
,93
,97
,93
,93
,90
,100
,100
,100

]

recall1 = [49
,86
,86
,86
,86
,86
,88
,86
,100

]
recnorm1=[95
,88
,91
,88
,88
,86
,93
,88
,95
]

f1_score1 =[49
,89
,92
,89
,89
,88
,94
,89
,87

]
f1norm1=[96
,90
,94
,90
,90
,88
,96
,94
,98

]

x = np.arange(len(Model))
width = 0.3

x

fig, ax = plt.subplots()
fig.set_size_inches(10, 6)

bar1 = ax.bar(x, precision1, width, label='precision',color = '#68bb59')
bar2 = ax.bar(x + width, recall1, width, label='recall',color = '#296d98')
bar3 = ax.bar(x + width*2, f1_score1, width, label='f1',color="#f48020")

ax.set_ylabel('Score(in %)')
ax.set_xlabel('Models')
ax.set_title('Results Comparison')
ax.set_xticks(x+width,Model)
ax.legend(loc="lower center")

#setting bar labels
ax.bar_label(bar1,fontsize=10)
ax.bar_label(bar2,fontsize=10)
ax.bar_label(bar3,fontsize=10)

fig.tight_layout()
plt.savefig("results_before_norm.jpeg")
plt.show()

fig, ax = plt.subplots()
fig.set_size_inches(10, 6)

bar1 = ax.bar(x, prnorm1, width, label='precision',color = '#68bb59')
bar2 = ax.bar(x + width, recnorm1, width, label='recall',color = '#296d98')
bar3 = ax.bar(x + width*2, f1norm1, width, label='f1',color = "#f48020")

ax.set_ylabel('Score(in %)')
ax.set_xlabel('Models')
ax.set_title('Result Comparison')
ax.set_xticks(x+width,Model)
ax.legend(loc="lower center")

#setting bar labels
ax.bar_label(bar1,fontsize=10)
ax.bar_label(bar2,fontsize=10)
ax.bar_label(bar3,fontsize=10)

fig.tight_layout()
plt.savefig("results_after_normalization.jpeg")
plt.show()